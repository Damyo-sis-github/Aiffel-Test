{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T01:08:40.553785Z","iopub.execute_input":"2022-07-08T01:08:40.554163Z","iopub.status.idle":"2022-07-08T01:08:40.562337Z","shell.execute_reply.started":"2022-07-08T01:08:40.554133Z","shell.execute_reply":"2022-07-08T01:08:40.561318Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"●만약 데이터 사이언스, 머신러닝 또는 캐글에서 어떤 것을 해야하는지 잘 모르는 newbie라면, 타이타닉을 하시는게 가장 좋은 선택입니다.\n\n●타이타닉은 아시다시피, 사상 최대 해난사고로써, 1,500여명의 희생자가 생겼습니다.\n\n●우리는 이 튜토리얼에서 타이타닉에 탑승한 사람들의 신상정보를 활용하여, 승선한 사람들의 생존여부를 예측하는 모델을 생성할 것입니다.\n\n●본 튜토리얼에서는 여러 시각화 도구(matplotlib,seaborn,plotly),데이터 분석 도구 (pandas,numpy),머신러닝 도구(sklearn)을 사용할 것입니다.\n\n●본 튜토리얼은 캐글에 있는 여러 커널들을 참조하여 만들었습니다. 본 튜토리얼을 공부하신 뒤에, 캐글 타이타닉 컴퍼티션(경쟁)에 존재하는 여러 다른 커널들을 더 공부하시면 됩니다.\n\n●본 튜토리얼은 파이썬 문법에 어려움이 없으셔야 수월할 것입니다. 여기서 사용하는 라이브러리들을 써본 경험이 있으면 좋겠지만, 경험이 없다하더라도 한줄씩 천천히 적어나가시면 충분히 하실 수 있습니다.","metadata":{}},{"cell_type":"code","source":"import numpy as np # 행렬때 필요한 라이브러리\nimport pandas as pd # 데이터 조작 및 분석을 위해 쓰는 라이브러리\nimport matplotlib.pyplot as plt #시각화 라이브러리\nimport seaborn as sns #Matplotlib 기반의 색상 테마와 통계용 차트 등의 기능을 추가한 시각화 패키지\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5)\n# 위 두줄은 본 필자가 항상 쓰는 방법\n# matplotlib의 기본 scheme말고 seaborn scheme을 세팅하고\n#일일이 graph의 font size를 지정할 필요 없이 seaborn의 font_scale을 사용하면 편합니다.\nimport missingno as msno #결측데이터들을 파악하는데 직곽적인 도움을 주는 패키\n\n#ignore warnings # 경고 메시지 무시하고 싶을때\nimport warnings \nwarnings.filterwarnings('ignore')\n# warnings.filterwarnings(action='default') #경고메시지 활성\n\n# Rich output에 대한 표현방식[출력옵션] (도표와 같은 그림, 소리, 애니메이션과 같은 결과물을 Rich output)\n%matplotlib inline \n# %matplotlib inline =>notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것\n# %로 시작하는 코드는 매직 코드 중 일부\n# 매직코드는 라인 유형과 셀 유형이 존대\n# 라인 매직에는 %문자가 접두어로 붙으면 OS명령줄 호출과 유사하게 작동\n# 라인의 나머지 부분은 인수로 가져오며 인자는 괄호나 따옴표 없이 전달\n# 라인 매직은 결과 반환할 수 있다\n\n#셀 매직은 %%문자가 접두어로 붙으며, 해당 줄을 포함하여 그 아랫줄도 인자로 넘어갈 수 있다.","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:42.008956Z","iopub.execute_input":"2022-07-08T01:08:42.009643Z","iopub.status.idle":"2022-07-08T01:08:42.650310Z","shell.execute_reply.started":"2022-07-08T01:08:42.009607Z","shell.execute_reply":"2022-07-08T01:08:42.649463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"***[탐색적 데이터 분석(EDA)과정에서 수행하기 좋은 결측치 시각화에 대해서 정리*]**\n* 결측치 시각화 방법 2가지 (seaborn / missingno)\n* seaborn을 이용하는 1가지, missingno을 이용하는 4가지\n\n[seaborn]은 matplotlib가 import된 상태에서만 작동\n[missingno]은 여러 관점에서의 결측치 시각화를 보고 싶을 때 쓰는편이다.","metadata":{}},{"cell_type":"markdown","source":"앞으로 우리가 해야할 프로세스는 대략 아래와 같습니다.\n\n1. [데이터셋 확인]\n- 대부분의 캐글 데이터들은 잘 정제되어 있습니다. 하지만 가끔 null data가 존재합니다. 이를 확인하고, 향후 수정합니다.\n\n2. [탐색적 데이터 분석 : exploratory data analysis]\n- 여러 feature들 간의 상관관계를 확인합니다. 여러 시각화 툴을 사용하여 insight를 얻습니다.\n\n3. [feature engineering]\n- 모델을 세우기에 앞서, 모델의 성능을 높일 수 있도록 feature들을 engineering합니다. one-hot encoding, class로 나누기, 구간으로 나누기, 텍스트 데이터 처리 등을 합니다.\n\n4. [model 만들기]\n- sklearn(사이킷런)을 이용해 모델을 만듭니다. 파이썬에서 머신러닝을 할 때는 sklearn을 사용하면 수많은 알고리즘을 일관된 문법으로 사용할 수 있습니다. 물론 딥러닝을 위해 tensorflow, pytorch 등을 사용할 수 도 있습니다.\n\n5. [모델 학습 및 예측 ]\n- trainset을 가지고 모델을 학습시킨 후, testset을 가지고 prediction(예측) 합니다.\n\n6. [모델 평가]\n- 예측 성능이 원하는 수준인지 판단합니다. 풀려는 문제에 따라 모델을 평가하는 방식도 달라집니다. 학습된 모델이 어떤 것을 학습하였는지 확인해봅니다.\n","metadata":{}},{"cell_type":"markdown","source":"# **1.Dataset 확인**\n\n▶ 파이썬에서 테이블화 된 데이터를 다루는데 가장 최적화되어 있으며, 많이 쓰이는 라이브러리는 pandas입니다.\n\n▶ 우리는 pandas를 사용하여 데이터셋의 간단한 통계적 분석부터 복잡한 처리들을 간단한 메소드를 사용하여 해낼 수 있습니다. \n\n▶ 파이썬으로 데이터분석을 한다고 하면 반드시 능숙해져야 할 라이브러리, 여러 커널들을 공부하시면서 사용법에 익숙해지도록 반복 또 반복하실기 권장합니다.\n\n▶ 캐글에서 Dataset은 보통 train, testset으로 나뉘어 있습니다.","metadata":{}},{"cell_type":"code","source":"# data load\ndf_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:43.936703Z","iopub.execute_input":"2022-07-08T01:08:43.937284Z","iopub.status.idle":"2022-07-08T01:08:43.966613Z","shell.execute_reply.started":"2022-07-08T01:08:43.937252Z","shell.execute_reply":"2022-07-08T01:08:43.965710Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"pandas에서 데이터를 확인하는 방법\n\nhead() : 데이터의 상단(상위 5개의 행)부분만 보여줌\n\ntail() : 데이터의 하단(하위 5개의 행)부분만 보여줌","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:45.532621Z","iopub.execute_input":"2022-07-08T01:08:45.533003Z","iopub.status.idle":"2022-07-08T01:08:45.559308Z","shell.execute_reply.started":"2022-07-08T01:08:45.532970Z","shell.execute_reply":"2022-07-08T01:08:45.558185Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"▶ 우리가 다루는 문제에서 feature는 Pclass,Age,SibSp, Parch, Fare이며, 예측하려는 target label은 Survived입니다.","metadata":{}},{"cell_type":"markdown","source":"|변수</br>(feature,varialve)|정의|설명|타입|\n|:-------------------:|:--:|:--:|:--:|\n|survival|생존여부 |target label임</br>1,0으로 표현됨|integer|\n|Pclass|티켓의 클래스|1 = 1st, 2 = 2nd, 3 = 3rd</br> 클래스로 나뉘며</br> categorical feature|integer\n|sex|성별|male, female로</br>구분되며 binary|string\n|Age|나이|continuous|integer\n|sibSp|함께 탑승한 형제와</br>배우자의 수|quantitative|integer\n|parch|함께 탑승한 부모</br>아이의수|quantitative|integer\n|ticket|티켓번호|alphabat + integer|string\n|fare|탑승료|continuous|float\n|cabin|객실번호|alphabat + integer|string\n|embared|탑승항구|C = Cherbourg</br>Q = Queenstown</br>S = Southampton|string","metadata":{}},{"cell_type":"markdown","source":"▶ pandas dataframe에는 describe() 메소드가 있는데, 이를 쓰면 각 feature가 가진 통계치들을 반환해줍니다.","metadata":{}},{"cell_type":"code","source":"# pandas data 프레임에는 describe 메서드가 있음\n# train data의 대략적인 수치들을 보여줌\n\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:46.410440Z","iopub.execute_input":"2022-07-08T01:08:46.411362Z","iopub.status.idle":"2022-07-08T01:08:46.455672Z","shell.execute_reply.started":"2022-07-08T01:08:46.411312Z","shell.execute_reply":"2022-07-08T01:08:46.454623Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:47.258849Z","iopub.execute_input":"2022-07-08T01:08:47.259250Z","iopub.status.idle":"2022-07-08T01:08:47.288825Z","shell.execute_reply.started":"2022-07-08T01:08:47.259217Z","shell.execute_reply":"2022-07-08T01:08:47.287496Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"▶ 테이블에서 보다시피, Passenser ID 숫자와 다른, 그러니까 null data가 존재하는 열(feature)가 있는 것 같습니다.\n\n▶ 이를 좀 더 보기 편하도록 그래프로 시각화해서 살펴봅시다.","metadata":{}},{"cell_type":"markdown","source":"# 1.1 Null data check","metadata":{}},{"cell_type":"code","source":"# 변수마다 몇 %의 결측치가 있는지 확인할 수 있는 코드\nfor col in df_train.columns :\n    msg = 'colum : {:>10}\\t Percent of NaN value : {:.2f}%'.format(col, 100 *(df_train[col].isnull().sum()/ df_train[col].shape[0]))\n    print(msg)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:48.134837Z","iopub.execute_input":"2022-07-08T01:08:48.135195Z","iopub.status.idle":"2022-07-08T01:08:48.145848Z","shell.execute_reply.started":"2022-07-08T01:08:48.135165Z","shell.execute_reply":"2022-07-08T01:08:48.144817Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\nmsg = 'colum : {:>10}\\t Percent of NaN value : {:.2f}%'.format(col, 100 (df_train[col].isnull().sum()/ df_train[col].shape[0]))\n\n* {:>10} : 오른쪽 정렬\n* {:.2f} : 소수점 둘째자리까지 출력\n* df_train[col].isnull().sum() : 해당 열의 결측치가 몇개인지 알 수 있게하는 문자\n   </br>  (TRUE = 1 (결측치), FALSE = 0 으로 계산)\n* df_train[col].shape[0] : 해달 열의 차원\n </br>  (열이 지정되어 있으므로 행의 갯수를 보여줌)\n* 100 * (df_train[col].isnull().sum()/ df_train[col].shape[0] :</br> 100 * (결측지/전체 데이터)를 의미하며,  %를 출력해주는 문장","metadata":{}},{"cell_type":"code","source":"for col in df_test.columns:\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0]))\n    print(msg)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:48.956569Z","iopub.execute_input":"2022-07-08T01:08:48.957324Z","iopub.status.idle":"2022-07-08T01:08:48.971043Z","shell.execute_reply.started":"2022-07-08T01:08:48.957281Z","shell.execute_reply":"2022-07-08T01:08:48.969443Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"* Train, Test set 에서 Age(둘다 약 20%), Cabin(둘다 약 80%), Embarked(Train만 0.22%) null data 존재하는 것을 볼 수 있습니다.\n\n* MANO라는 라이브러리를 사용하면 null data의 존재를 더 쉽게 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"#missingno 패키지 (애칭 : msno) : 결측데이터들을 파악하는데 직관적인 도움을 주는 패키\nmsno.matrix(df=df_train.iloc[:,:], figsize=(8,8), color=(0.8,0.5,0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:49.767613Z","iopub.execute_input":"2022-07-08T01:08:49.767991Z","iopub.status.idle":"2022-07-08T01:08:50.157476Z","shell.execute_reply.started":"2022-07-08T01:08:49.767961Z","shell.execute_reply":"2022-07-08T01:08:50.156335Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\nmsno.matrix(df=df_train.iloc[:,:], figsize=(8,8), color=(0.8,0.5,0.2))\n\n* msno.matrix : 행렬 형태로 데이터를 보여줌\n* .iloc : 행번호로 선택\n* msno.bar 바 형태로 데이터를 보여줌\n* figsize = (가로 길이, 세로 길이)\n* color = (R,G,B) #(1,1,1)이 흰색임","metadata":{}},{"cell_type":"code","source":"msno.bar(df = df_train.iloc[:,:], figsize=(8,8), color=(0.8,0.5,0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:50.575083Z","iopub.execute_input":"2022-07-08T01:08:50.575505Z","iopub.status.idle":"2022-07-08T01:08:51.444131Z","shell.execute_reply.started":"2022-07-08T01:08:50.575470Z","shell.execute_reply":"2022-07-08T01:08:51.442848Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"msno.bar(df = df_test.iloc[:,:], figsize=(8,8), color=(0.8,0.5,0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:51.446501Z","iopub.execute_input":"2022-07-08T01:08:51.447857Z","iopub.status.idle":"2022-07-08T01:08:52.300629Z","shell.execute_reply.started":"2022-07-08T01:08:51.447802Z","shell.execute_reply":"2022-07-08T01:08:52.299332Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Target label 확인\n\n* target label 이 어떤 distribution을 가지고 있는지 확인해봐야 합니다\n\n* 지금 같은 binary classification 문제의 경우에서, 1과 0의 분포가 어떠냐에 따라 모델의 평가 방법이 달라 질 수 있습니다. ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18,8))\n\ndf_train['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=df_train, ax=ax[1])\nax[1].set_title('Count plot - Survived')\n\nplt. show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:52.303280Z","iopub.execute_input":"2022-07-08T01:08:52.304799Z","iopub.status.idle":"2022-07-08T01:08:52.626495Z","shell.execute_reply.started":"2022-07-08T01:08:52.304738Z","shell.execute_reply":"2022-07-08T01:08:52.625432Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\nf, ax = plt.subplots(1, 2, figsize=(18,8)) # f는 행 ax는 열\n\ndf_train['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=df_train, ax=ax[1])\nax[1].set_title('Count plot - Survived')\n\nplt. show()\n\n-------------------------------------------------\n* subplot(row,column) : 한개의 행의 2개로 나눠진 열을 준비  (그래서 위의 코드는 가로 2개의 그래프 출력)\n\n* value_counts : 지정해준 field의 value별 개수를 알려줌 즉, Survived는 0과 1로 이루어진 데이터인데, 각각의 값이 얼마나 있는지 알려줌\n\n* plot.pie : 파이 그래프를 생성(기본은 약간 타원형), expand를 통해 확장, autopct를 통해 나오는 수치를 percent범위를 지정\n\n* f는 행, ax는 열을 의미함, 그래서 ax=ax[0]은 가로의 0번째 자리 즉, 첫번째 자리에 그림을 그리겠다는 의미\n\n* set_ylabel('') : y축의 이름을 없앤다는 설정\n\n* countplot은 각 value의 개수를 막대그리프로 보여","metadata":{}},{"cell_type":"markdown","source":"* 안타깝게도 죽은 사람이 많습니다.\n\n* 38.4%가 살아남았습니다.\n\n* target label의 분포가 제법 균일(balanced)gkqslek. 불균일할 경우, 예를 들어 100중 1이 99, 0이 1개인 경우에는 만약 모델이 모든것을 1이라해도 정확도가 99%가 나오게 됩니다. 0을 찾는 문제라면 이 모델은 원하는 결과를 줄 수 없게 됩니다. 지금 문제에서는 그렇지 않으니 계속 진행하겠습니다. ","metadata":{}},{"cell_type":"markdown","source":"# 2 Exploratory data analysis\n\n* 이제 본격적으로 데이터 분석을 해보겠습니다. 데이터는 매우 많습니다. 이 많은 데이터 안에 숨겨진 사실을 찾기 위해선 적절한 시각화가 필요합니다.\n\n* 시각화 라이브러리는 matplotlib, seaborn, plotly 등이 있습니다. 특정 목적에 맞는 소스코드를 정리해두어 필요할 때마다 참고하면 편합니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Pclass\n\n* 먼저 Pclass에 대해서 살펴보겠습니다. Pclass는 ordinal, 서수형 데이터입니다. 카테고리이면서, 순서가 있는 데이터 타입입니다. \n\n* 먼저 Pclass에 따른 생존률의 차이를 살펴보겠습니다. 엑셀의 피벗 차트와 유사한 작업을 하게 되는데, pandas dataframe에서는 groupby를 사용하면 쉽게 할 수 있습니다. 또한 pivot이라는 메소드도 있습니다\n\n* 'Pclass', \"Survived'를 가져온 후, pclass로 묶습니다. 그러고나면 각 pclass마다 0,1이 count가 되는데, 이를 평균내면 각 pclass 별 생존률이 나옵니다.\n\n* 아래와 같이 count()를하면, 각 class에 몇명이 있는지 확인할 수 있으며, sum()을 하면, 216명중 생존한(survived=1)사람의 총합을 주게됩니다.","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass','Survived']].groupby(['Pclass'], as_index=True).count()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:52.996747Z","iopub.execute_input":"2022-07-08T01:08:52.997188Z","iopub.status.idle":"2022-07-08T01:08:53.013851Z","shell.execute_reply.started":"2022-07-08T01:08:52.997152Z","shell.execute_reply":"2022-07-08T01:08:53.012671Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\n\n* count를 통해서 value에 해당하는 sample이 몇개있는지 알려줌\n\n* [[]]와 같이 이중 list로(리스트로 데이터를 묶어서) field를 설정해줘야한다\n\n* as_index는 묶어서 field를 index로 설정할지를 결정하며, True로 설정\n\n* sum을 사용할 경우, 각 data들의 합을 반환한다. ","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass','Survived']].groupby(['Pclass'], as_index=True).sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:53.861241Z","iopub.execute_input":"2022-07-08T01:08:53.861648Z","iopub.status.idle":"2022-07-08T01:08:53.877182Z","shell.execute_reply.started":"2022-07-08T01:08:53.861615Z","shell.execute_reply":"2022-07-08T01:08:53.876365Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"* pandas의 crosstab을 사용하면 좀 더 위 과정을 좀 더 수월하게 볼 수 있습니다","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:54.624432Z","iopub.execute_input":"2022-07-08T01:08:54.625510Z","iopub.status.idle":"2022-07-08T01:08:54.738844Z","shell.execute_reply.started":"2022-07-08T01:08:54.625473Z","shell.execute_reply":"2022-07-08T01:08:54.737762Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\n\n* mean을 통해서 각 class별 생존율을 얻을 수 있음\n\n* style.background_gradient로 데이터 범위에 따른 색상을 설정\n\n* cmap은 color map으로 google을 통해 다양한 테마를 확인가","metadata":{}},{"cell_type":"markdown","source":"* grouped 객체에 mean()을 하게되면 각 클래스별 생존률을 얻을 수 있습니다. class 1이면 아래와 같습니다.\n\n# $$ \\frac{80}{80+136} \\approx 0.63$$","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass','Survived']].groupby(['Pclass'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:55.379747Z","iopub.execute_input":"2022-07-08T01:08:55.380158Z","iopub.status.idle":"2022-07-08T01:08:55.571006Z","shell.execute_reply.started":"2022-07-08T01:08:55.380122Z","shell.execute_reply":"2022-07-08T01:08:55.570223Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\n\n* sort_values(by='기준', ascending=False)을 통해서 정렬 by뒤에 정렬기준을 설정하고 ascending=False이면 내림차순 정","metadata":{}},{"cell_type":"markdown","source":"* 보다시피 Pclass가 좋을수록(1st) 생존률이 높은 것을 확인할 수 있습니다.\n\n* 좀 더 보기 쉽게 그래프를 그려보겠습니다. seaborn의 countplot을 이용하면, 특정 label에 따른 개수를 확인해볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"y_position = 1.02\nf, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])\nax[0].set_title('Number of Passengers By Pclass', y=y_position)\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Pclass: Survived vs Dead', y=y_position)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:56.159071Z","iopub.execute_input":"2022-07-08T01:08:56.159661Z","iopub.status.idle":"2022-07-08T01:08:56.465474Z","shell.execute_reply.started":"2022-07-08T01:08:56.159621Z","shell.execute_reply":"2022-07-08T01:08:56.464369Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### **코드 해석**\n\n* 왼쪽 그래프는 Pclass별 승객수를 나타내는 bar그래프\n\n* 오른쪽 그래프는 각 Pclass별 생존자와 사망자수를 비교하여 나타낸다 여기서,hue는 나눠주는 기준 </br>\n..sns.countplot은 seaborn의 countplot으로 특정 label에 따른 항목의 개수 파악에 유리함\n\n* 즉, class 높아질수록 생존율이 높아지고, class가 생존율에 큰 영향을 미치는 feature임을 파악할 수 있음.\n","metadata":{}},{"cell_type":"markdown","source":"* 클래스가 높을수록 생존 확률이 높은걸 확인할 수 있습니다. Pclass 1, 2, 3 순서대로 63%, 48%, 25% 입니다.\n\n* 우리는 생존에 Pclass가 큰 영향을 미친다고 생각해볼 수 있으며, 나중에 모델을 세울 때 이 feature를 사용하는 것이 좋을 것이라 판단할 수 있습니다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Sex\n\n* 이번에는 성별로 생존률이 어떻게 달라지는지 확인해보겠습니다.\n\n* 마찬가지로 pandas groupby와 seaborn countplot을 사용해서 시각화해봅시다","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train[['Sex','Survived']].groupby(['Sex'], as_index=True).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Sex: Survived vs Dead')\n\nplt. show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:56.986839Z","iopub.execute_input":"2022-07-08T01:08:56.987229Z","iopub.status.idle":"2022-07-08T01:08:57.335738Z","shell.execute_reply.started":"2022-07-08T01:08:56.987196Z","shell.execute_reply":"2022-07-08T01:08:57.334454Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피 여자가 생존할 확률이 높습니다.","metadata":{}},{"cell_type":"code","source":"df_train[['Sex','Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:57.746793Z","iopub.execute_input":"2022-07-08T01:08:57.747653Z","iopub.status.idle":"2022-07-08T01:08:57.764273Z","shell.execute_reply.started":"2022-07-08T01:08:57.747609Z","shell.execute_reply":"2022-07-08T01:08:57.763195Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df_train['Sex'],df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:58.478778Z","iopub.execute_input":"2022-07-08T01:08:58.479186Z","iopub.status.idle":"2022-07-08T01:08:58.527887Z","shell.execute_reply.started":"2022-07-08T01:08:58.479150Z","shell.execute_reply":"2022-07-08T01:08:58.526803Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"* Pclass와 마찬가지로 Sex도 예측모델에 쓰일 중요한 feature임을 알 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.3 Both Sex and Pclass\n\n* 이번에는 Sex, Pclass 두가지에 관하여 생존이 어떻게 달라지는지 확인해봅시다\n\n* seaborn의 factorplot을 이용하면, 손쉽게 3개의 차원으로 이루어진 그래프를 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"# factorplot\n# X축은 Pclass,Y축은 Survived\nsns.factorplot('Pclass','Survived',hue='Sex', data= df_train, size=6, aspect=1.5)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:08:59.186663Z","iopub.execute_input":"2022-07-08T01:08:59.187041Z","iopub.status.idle":"2022-07-08T01:08:59.824801Z","shell.execute_reply.started":"2022-07-08T01:08:59.187010Z","shell.execute_reply":"2022-07-08T01:08:59.823713Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"* 모든 클래스에서 female이 살 확률이 male보다 높은 걸 알 수 있습니다. \n\n* 또한, 남자, 여자 상관없이 클래스가 높을수록 살 확률이 높습니다.\n\n* 위 그래프는 hue 대신 column으로 하면 아래와 같아집니다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x=\"Sex\",y='Survived', col='Pclass', data=df_train, satureation=.5, size =9, aspect=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:00.166782Z","iopub.execute_input":"2022-07-08T01:09:00.167146Z","iopub.status.idle":"2022-07-08T01:09:01.169335Z","shell.execute_reply.started":"2022-07-08T01:09:00.167114Z","shell.execute_reply":"2022-07-08T01:09:01.168261Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Age\n\n* 이번에는 Age feature를 살펴봅시다","metadata":{}},{"cell_type":"code","source":"print('제일 나이 많은 탑승객 : {:.1f} Years'.format(df_train['Age'].max()))\nprint('제일 어린 탑승객 : {:.1f} Years'.format(df_train['Age'].min()))\nprint('탑승객 평균 나이 : {:.1f} Years'.format(df_train['Age'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:01.171011Z","iopub.execute_input":"2022-07-08T01:09:01.171353Z","iopub.status.idle":"2022-07-08T01:09:01.179342Z","shell.execute_reply.started":"2022-07-08T01:09:01.171323Z","shell.execute_reply":"2022-07-08T01:09:01.178225Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"* 생존에 따른 Age의 histogram을 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(9,5))\n\nsns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax=ax)\nsns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax=ax)\n\nplt.legend(['Survived ==1', 'Survived ==0'])\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:01.600487Z","iopub.execute_input":"2022-07-08T01:09:01.601199Z","iopub.status.idle":"2022-07-08T01:09:01.888776Z","shell.execute_reply.started":"2022-07-08T01:09:01.601156Z","shell.execute_reply":"2022-07-08T01:09:01.887616Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 생존자 중 나이가 어린 경우가 많음을 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"# Age distribution withing classes\nplt.figure(figsize=(8,6))\ndf_train['Age'][df_train['Pclass']==1].plot(kind='kde')\ndf_train['Age'][df_train['Pclass']==2].plot(kind='kde')\ndf_train['Age'][df_train['Pclass']==3].plot(kind='kde')\n\nplt.xlabel('Age')\nplt.title('Age distribution within classes')\nplt.figlegend(['1st Class','2nd Class','3rd Class'])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:02.358722Z","iopub.execute_input":"2022-07-08T01:09:02.359107Z","iopub.status.idle":"2022-07-08T01:09:02.634635Z","shell.execute_reply.started":"2022-07-08T01:09:02.359075Z","shell.execute_reply":"2022-07-08T01:09:02.633543Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"* Class가 높을수록 나이 많은 사람의 비중이 커짐\n\n* 나이대가 변하면서 생존률이 어떻게 되는지 보려고 합니다 \n\n* 나이범위를 점점 넓혀가며, 생존률이 어떻게 되는지 한번 봅시다.","metadata":{}},{"cell_type":"code","source":"cummulate_survival_ratio = []\nfor i in range(1, 80):\n    cummulate_survival_ratio.append(df_train[df_train['Age'] < i]['Survived'].sum() / len(df_train[df_train['Age'] < i]['Survived']))\n    \nplt.figure(figsize=(7, 7))\nplt.plot(cummulate_survival_ratio)\nplt.title('Survival rate change depending on range of Age', y=1.02)\nplt.ylabel('Survival rate')\nplt.xlabel('Range of Age(0~x)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:03.064798Z","iopub.execute_input":"2022-07-08T01:09:03.065170Z","iopub.status.idle":"2022-07-08T01:09:03.339066Z","shell.execute_reply.started":"2022-07-08T01:09:03.065138Z","shell.execute_reply":"2022-07-08T01:09:03.338326Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피 나이가 어릴수록 생존률이 확실히 높은것을 확인할 수 있습니다.\n\n* 우리는 이 나이가 중요한 feature로 쓰일 수 있음을 확인했습니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.5 Pclass, Sex, Age\n\n* 지금까지 본 Sex, Pclass, Age, Survived 모두에 대해서 보고싶습니다. 이를 쉽게 그려주는 것이 seaborn의 violinplot입니다.\n\n* x축은 우리가 나눠서 보고싶어하는 case(여기선 Pclass, Sex)를 나타내고, y축은 보고 싶어하는 distribution(Age)입니다.\n\n* 한번 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"# split =True은 그래프를 겹쳐보여주는것\n# set_yticks y축 단\n\nf,ax=plt.subplots(1,2,figsize=(18,8))\nsns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=df_train, scale='count', split=True,ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=df_train, scale='count', split=True,ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:03.708977Z","iopub.execute_input":"2022-07-08T01:09:03.709618Z","iopub.status.idle":"2022-07-08T01:09:04.247595Z","shell.execute_reply.started":"2022-07-08T01:09:03.709568Z","shell.execute_reply":"2022-07-08T01:09:04.246557Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"* 왼쪽 그림은 Pclass별로 Age의 distribution이 어떻게 다른지, 거기에 생존여부에 따라 구분한 그래프입니다.\n\n* 오른쪽 그림도 마찬가지 Sex, 생존에 따른 distribution이 어떻게 다른지 보여주는 그래프입니다.\n\n* 생존만 봤을 때, 모든 클래스에서 나이가 어릴수록 생존을 많이 한것을 볼 수 있습니다.\n\n* 오른쪽 그림에서 보면, 명확히 여자가 생존을 많이 한것을 볼 수 있습니다.\n\n* 여성과 아이를 먼저 챙긴 것을 볼 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.6 Embarked\n\n* Embarked는 탑승한 항구를 나타냅니다. \n\n* 위에서 해왔던 것과 비슷하게 탑승한 곳에 따른 생존률을 보겠습니다. ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,1,figsize=(7,7))\n\ndf_train[['Embarked','Survived']].groupby([\"Embarked\"], as_index=True).mean().sort_values(by='Survived',ascending=False).plot.bar(ax=ax)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:04.314535Z","iopub.execute_input":"2022-07-08T01:09:04.315479Z","iopub.status.idle":"2022-07-08T01:09:04.520128Z","shell.execute_reply.started":"2022-07-08T01:09:04.315431Z","shell.execute_reply":"2022-07-08T01:09:04.518742Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, 조금의 차이는 있지만 생존률은 좀 비슷한 거 같습니다. 그래도 C가 제일 높군요\n\n* 모델에 얼마나 큰 영향을 미칠지는 모르겠지만, 그래도 사용하겠습니다.\n\n* 사실, 모델을 만들고 나면 우리가 사용한 feature들이 얼마나 중요한 역할을 했는지 확인해볼 수 있습니다. 이는 추후에 모델을 만들고 난 다음에 살펴볼 것입니다.\n\n* 다른 feature로 split하여 한번 살펴보겠습니다.","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(2,2,figsize=(20,15))\n\nsns.countplot('Embarked', data=df_train, ax=ax[0,0])\nax[0,0].set_title('(1) No. Of Passengers Boarded')\n\nsns.countplot('Embarked',hue=\"Sex\", data=df_train, ax=ax[0,1])\nax[0,1].set_title('(2) Male-Female Split for Embarked')\n\nsns.countplot('Embarked', hue='Survived',data=df_train, ax=ax[1,0])\nax[1,0].set_title('(3) Embarked vs Survived')\n\nsns.countplot('Embarked', hue=\"Pclass\", data=df_train, ax=ax[1,1])\nax[1,1].set_title('(4) Embarked vs Pclass')\n\nplt.subplots_adjust(wspace =0.2, hspace=0.5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:04.872604Z","iopub.execute_input":"2022-07-08T01:09:04.872998Z","iopub.status.idle":"2022-07-08T01:09:05.524455Z","shell.execute_reply.started":"2022-07-08T01:09:04.872961Z","shell.execute_reply":"2022-07-08T01:09:05.523422Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"* Figure(1) - 전체적으로 봤을 때, S에서 가장 많은 사람이 탑승했습니다.\n\n* Figure(2) - C와 Q는 남녀의 비율이 비슷하고, S는 남자가 더 많습니다.\n\n* Figure(3) - 생존확률이 S의 경우 많이 낮은걸 볼 수 있습니다.(이전 그래프에 봤었습니다.)\n\n* Figure(4) - Class로 Split해서 보니, C가 생존확률이 높은건 클래스가 높은 사람이 많이 타서 그렇습니다. S는 3rd class가 많아서 생존확률이 낮게 나옵니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.7 Family- SibSp(형제자매) + Parch(부모,자녀)\n\n* SibSp와 Parch를 합하면 Family가 될 것입니다. Family로 합쳐서 분석해봅시다","metadata":{}},{"cell_type":"code","source":"df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:05.526194Z","iopub.execute_input":"2022-07-08T01:09:05.526538Z","iopub.status.idle":"2022-07-08T01:09:05.534843Z","shell.execute_reply.started":"2022-07-08T01:09:05.526507Z","shell.execute_reply":"2022-07-08T01:09:05.533573Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"Maximum size of Family : \",df_train['FamilySize'].max())\nprint(\"Minimum size of Family : \",df_train['FamilySize'].min())\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:06.210833Z","iopub.execute_input":"2022-07-08T01:09:06.211200Z","iopub.status.idle":"2022-07-08T01:09:06.218038Z","shell.execute_reply.started":"2022-07-08T01:09:06.211171Z","shell.execute_reply":"2022-07-08T01:09:06.216982Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"* FamilySize와 생존의 관계를 한번 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(1, 3, figsize=(40,10))\nsns.countplot('FamilySize', data=df_train, ax=ax[0])\nax[0].set_title('(1) No. Of Passengers Boarded', y=1.02)\n\nsns.countplot('FamilySize', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('(2) Survived countplot depending on FamilySize',  y=1.02)\n\ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])\nax[2].set_title('(3) Survived rate depending on FamilySize',  y=1.02)\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:06.784939Z","iopub.execute_input":"2022-07-08T01:09:06.785549Z","iopub.status.idle":"2022-07-08T01:09:07.435898Z","shell.execute_reply.started":"2022-07-08T01:09:06.785488Z","shell.execute_reply":"2022-07-08T01:09:07.434773Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"* Figure (1) - 가족크기가 1~11까지 있음을 볼 수 있습니다. 대부분 1명이고 그 다음으로 2,3,4명입니다.\n\n* Figure (2),(3) - 가족 크기에 따른 생존 비교입니다. 가족이 4명인 경우가 가장 생존확률이 높습니다. 가족수가 많아질수록 (5,6,7,8,11) 생존확률이 낮아지네요. 가족수가 너무 작아도(1), 너무 커도(5,6,8,11) 생존확률이 작네요. 3~4명 선에서 생존확률이 높은걸 확인할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.8 Fare\n\n* Fare는 탑승요금이며, contious feature 입니다. 한번 histogram을 그려보겠습니다.\n","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:07.437794Z","iopub.execute_input":"2022-07-08T01:09:07.438131Z","iopub.status.idle":"2022-07-08T01:09:07.789460Z","shell.execute_reply.started":"2022-07-08T01:09:07.438099Z","shell.execute_reply":"2022-07-08T01:09:07.788153Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, distribution이 매우 비대칭인 것을 알 수 있습니다 (high skewness). 만약 이대로 모델에 넣어준다면 자칫 모델이 잘못 학습할 수도 있습니다. 몇개 없는 outlier에 대해서 너무 민감하게 반응한다면, 실제 예측 시에 좋지 못한 결과를 부를 수도 있습니다.\n\n* outlier의 영향을 줄이기 위해 Fare에 log를 취하겠습니다.\n\n* 여기서 우리는 pandas의 유용한 기능을 사용할 겁니다. dataFrame의 특정 columns에 공통된 작업(함수)를 적용하고 싶으면 아래의 map,또는 apply를 사용하면 매우 손쉽게 적용할 수 있습니다.\n\n* 우리가 지금 원하는 것은 Fare columns의 데이터 모두를 log값 취하는 것인데, 파이썬의 간단한 lambda함수를 이용해 간단한 로그를 적용하는 함수를 map에 인수로 넣어주면, Fare columns 데이터에 그대로 적용이 됩니다. 매우 유용한 기능이니 꼭 숙지하세요!","metadata":{}},{"cell_type":"code","source":"# 아래 줄은 뒤늦게 발견하였습니다. 13번째 강의에 언급되니, 일단 따라치시고 넘어가면 됩니다.\n\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean() # testset 에 있는 nan value 를 평균값으로 치환합니다.\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:07.906995Z","iopub.execute_input":"2022-07-08T01:09:07.907364Z","iopub.status.idle":"2022-07-08T01:09:07.921036Z","shell.execute_reply.started":"2022-07-08T01:09:07.907332Z","shell.execute_reply":"2022-07-08T01:09:07.919688Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:08.454965Z","iopub.execute_input":"2022-07-08T01:09:08.455700Z","iopub.status.idle":"2022-07-08T01:09:08.772929Z","shell.execute_reply.started":"2022-07-08T01:09:08.455659Z","shell.execute_reply":"2022-07-08T01:09:08.771790Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"* log를 취하니 이제 비대칭성이 많이 사라진 것을 볼 수 있습니다\n\n* 우리는 이런 작업을 사용해 모델이 좀 더 좋은 성능을 내도록 할 수 있습니다.\n\n* 사실 방금한 것은 feature engineering에 들어가는 부분인데, 여기서 작업했습니다..\n\n* 모델을 학습시키기 위해, 그리고 그 모델의 성능을 높이기 위해 feature들에 여러 조작을 가하거나, 새로운 feature를 추가하는 것을 feature engineering이라고 하는데, 우리는 이제 그것을 살펴볼 것입니다.","metadata":{}},{"cell_type":"markdown","source":"## 2.9 Cabin\n\n* 이 feature는 NaN이 대략 80%이므로, 생존에 영향을 미칠 중요한 정보를 얻어내기가 쉽지 않습니다. \n\n* 그러므로 우리가 세우려는 모델에 포함시키지 않도록 하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:08.999941Z","iopub.execute_input":"2022-07-08T01:09:09.000342Z","iopub.status.idle":"2022-07-08T01:09:09.021080Z","shell.execute_reply.started":"2022-07-08T01:09:09.000310Z","shell.execute_reply":"2022-07-08T01:09:09.019616Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## 2.10 Ticket\n\n* 이 feature는 NaN은 없습니다. 일단 string data이므로 우리가 어떤 작업들을 해주어야 실제 모델에 사용할 수 있는데, 이를 위해선 사실 아이디어가 필요합니다.","metadata":{}},{"cell_type":"code","source":"df_train['Ticket'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:09:09.528736Z","iopub.execute_input":"2022-07-08T01:09:09.529372Z","iopub.status.idle":"2022-07-08T01:09:09.539022Z","shell.execute_reply.started":"2022-07-08T01:09:09.529322Z","shell.execute_reply":"2022-07-08T01:09:09.537967Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, ticket number는 매우 다양합니다. 우리는 여기서 어떤 특징을 이끌어내서 생존과 연결시킬 수 있을지 생각해보기!","metadata":{}},{"cell_type":"markdown","source":"# --------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import Series\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) # 이 두줄은 본 필자가 항상 쓰는 방법입니다. matplotlib 의 기본 scheme 말고 seaborn scheme 을 세팅하고, 일일이 graph 의 font size 를 지정할 필요 없이 seaborn 의 font_scale 을 사용하면 편합니다.\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n%matplotlib inline\n\ndf_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')\ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\n\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:47.272298Z","iopub.execute_input":"2022-07-08T01:42:47.272740Z","iopub.status.idle":"2022-07-08T01:42:47.311975Z","shell.execute_reply.started":"2022-07-08T01:42:47.272703Z","shell.execute_reply":"2022-07-08T01:42:47.310891Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"markdown","source":"# 3.Feature engineering\n\n* 본격적인 feature engineering을 시작해보겠습니다.\n* 가장 먼저,dataset에 존재하는 null data를 채우려고 합니다.\n* 아무 숫자로 채울 수는 없고, null data를 포함하는 feature의 statistice를 참고하거나, 다른 아이디어를 짜내어 채울 수 있습니다.\n* null data를 어떻게 채우느냐 따라 모델의 성능이 좌지우지될 수 있기 때문에, 신경써줘야할 부분입니다.\n* Feature engineering은 실제 모델의 학습에 쓰려고 하는 것이므로 train 뿐만 아니라 test도 똑같이 적용해주어야 합니다 잊지맙시다!~","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Fill Null\n\n### 3.1.1 Fill Null in Age using title\n\n* Age에는 null data가 177개나 있습니다. 이를 채울 수 있는 여러 아이디어가 있을 것인데 여기서 우리는 title + statistics를 사용해 보겠습니다\n\n* 영어에서는 Miss, Mrr, Mrs 같은 title이 존재합니다. 각 탑승객의 이름에는 꼭 이런 title이 들어가게 되는데 이를 사용해 보겠습니다.\n\n* pandas series에는 data를 string으로 바꿔주는 str method, 거기에 정규표현식을 적용하게 해주는 extract method가 있습니다. 이를 사용하여 title을 쉽게 추출할 수 있습니다. title을 lnitial column에 저장하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial']= df_train.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n    \ndf_test['Initial']= df_test.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:51.405275Z","iopub.execute_input":"2022-07-08T01:42:51.405657Z","iopub.status.idle":"2022-07-08T01:42:51.419577Z","shell.execute_reply.started":"2022-07-08T01:42:51.405626Z","shell.execute_reply":"2022-07-08T01:42:51.418239Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"markdown","source":"* pandas의 crosstab을 이용하여 우리가 추출한 lnitial과 sex간의 count를 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"# Checking the Initials with the Sex\npd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:52.430636Z","iopub.execute_input":"2022-07-08T01:42:52.431443Z","iopub.status.idle":"2022-07-08T01:42:52.481130Z","shell.execute_reply.started":"2022-07-08T01:42:52.431375Z","shell.execute_reply":"2022-07-08T01:42:52.480108Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"markdown","source":"* 위 table을 참고하여 남자, 여자가 쓰는 initial을 구분해 보겠습니다. replace 메소드를 사용하면, 특정 데이터 값을 원하는 값으로 치환해줍니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\n\ndf_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:53.097969Z","iopub.execute_input":"2022-07-08T01:42:53.098629Z","iopub.status.idle":"2022-07-08T01:42:53.112772Z","shell.execute_reply.started":"2022-07-08T01:42:53.098588Z","shell.execute_reply":"2022-07-08T01:42:53.111455Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:53.741233Z","iopub.execute_input":"2022-07-08T01:42:53.741626Z","iopub.status.idle":"2022-07-08T01:42:53.760388Z","shell.execute_reply.started":"2022-07-08T01:42:53.741594Z","shell.execute_reply":"2022-07-08T01:42:53.759252Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"markdown","source":"* 여성과 관계있는 Miss, Mr, Mrs가 생존률이 높은 것을 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial')['Survived'].mean().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:54.375632Z","iopub.execute_input":"2022-07-08T01:42:54.376425Z","iopub.status.idle":"2022-07-08T01:42:54.517958Z","shell.execute_reply.started":"2022-07-08T01:42:54.376371Z","shell.execute_reply":"2022-07-08T01:42:54.517082Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"* 이제 본격적으로 Nulldmf 채울 것입니다. null data를 채우는 방법은 정말 많이 존재합니다. statistics를 활용하는 방법도 있고, null data가 없는 데이터를 기반으로 새로운 머신러닝 알고리즘을 만들어 예측해서 채워넣는 방식도 있습니다. 여기서는 statistics를 활용하는 방법을 사용할 것입니다.\n\n* 여기서 statistics는 train data의 것을 의미합니다. 우리는 언제나 test를 unseen으로 둔 상태로 놔둬야 하며, train에서 얻은 statistics를 기반으로 test의 null data를 채워줘야 합니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:55.020494Z","iopub.execute_input":"2022-07-08T01:42:55.020906Z","iopub.status.idle":"2022-07-08T01:42:55.041022Z","shell.execute_reply.started":"2022-07-08T01:42:55.020870Z","shell.execute_reply":"2022-07-08T01:42:55.040075Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"markdown","source":"* Age의 평균을 이용해 Null Value를 채우도록 하겠습니다\n\n* pandas dataframe을 다룰 때에는 boolean array를 이용해 indexing하는 방법이 참으로 편리합니다.\n\n* 아래 코드 첫줄을 해석하자면, isnull()이면서 lnitial이 Mr인 조건을 만족하는 row(탑승객)의 'Age'의 값을 33으로 치환한다 입니다.\n\n* loc + boolean + column을 사용해 값을 치환하는 방법은 자주 쓰이므로 꼭 익숙해집시다.","metadata":{}},{"cell_type":"code","source":"df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46\n\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:55.635063Z","iopub.execute_input":"2022-07-08T01:42:55.635840Z","iopub.status.idle":"2022-07-08T01:42:55.659354Z","shell.execute_reply.started":"2022-07-08T01:42:55.635789Z","shell.execute_reply":"2022-07-08T01:42:55.658270Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"* 여기선 간단하게 Null을 채웠지만, 좀 더 다양한 방법을 쓴 예시들이 다른 커널에 존재합니다.\n\n* https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling 보시면서 공부해보세요\n\n* 이 외에도 다른 캐글러들의 커널을 보며 여러 참신한 아이디어를 살펴보세요 ","metadata":{}},{"cell_type":"markdown","source":"### 3.1.2 Fill Null in Embarked","metadata":{}},{"cell_type":"code","source":"print('Embarked has ', sum(df_train['Embarked'].isnull()), ' Null values')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:56.242687Z","iopub.execute_input":"2022-07-08T01:42:56.243658Z","iopub.status.idle":"2022-07-08T01:42:56.249671Z","shell.execute_reply.started":"2022-07-08T01:42:56.243617Z","shell.execute_reply":"2022-07-08T01:42:56.248822Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"* Embarkce는 Null value가 2개이고, S에서 가장 많은 탑승객이 있었으므로, 간단하게 Null을 S로 채우겠습니다.\n\n* dataframe의 fillna method를 이용하면 쉽게 채울 수 있습니다. 여기서 inplace = True로 하면 df_traindp fillna를 실제로 적용하게 됩니다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:42:58.442321Z","iopub.execute_input":"2022-07-08T01:42:58.443065Z","iopub.status.idle":"2022-07-08T01:42:58.451455Z","shell.execute_reply.started":"2022-07-08T01:42:58.443026Z","shell.execute_reply":"2022-07-08T01:42:58.450167Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'].fillna('S', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:00.130306Z","iopub.execute_input":"2022-07-08T01:43:00.131337Z","iopub.status.idle":"2022-07-08T01:43:00.139576Z","shell.execute_reply.started":"2022-07-08T01:43:00.131302Z","shell.execute_reply":"2022-07-08T01:43:00.138471Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Change Age </br>(continuous to categorical)\n\n* Age는 현재 contrinuous feature입니다. 이대로 써도 모델을 세울 수 있지만, Age를 몇개의 group으로 나누어 category화 시켜줄 수도 있습니다. contrinuous를 categorical로 바꾸면 자칫 information loss가 생길 수도 있습니다만, 본 튜토리얼에서는 다양한 방법을 소개하는 것이 목적이므로 진행하도록 하겠습니다.\n\n* 방법은 여러가지가 있습니다. dataframe의 indexing 방법인 loc를 사용하여 직접 해줄 수 있고, 아니면 apply를 사용해 함수를 넣어줄 수 있습니다\n\n* 첫번째로 loc를 사용한 방법입니다. loc는 자주쓰게 되므로 그 사용법을 숙지하시면 좋습니다. \n\n* 나이는 10살 간격으로 나누겠습니다. ","metadata":{}},{"cell_type":"code","source":"df_train['Age_cat'] = 0\ndf_train.loc[df_train['Age'] < 10, 'Age_cat'] = 0\ndf_train.loc[(10 <= df_train['Age']) & (df_train['Age'] < 20), 'Age_cat'] = 1\ndf_train.loc[(20 <= df_train['Age']) & (df_train['Age'] < 30), 'Age_cat'] = 2\ndf_train.loc[(30 <= df_train['Age']) & (df_train['Age'] < 40), 'Age_cat'] = 3\ndf_train.loc[(40 <= df_train['Age']) & (df_train['Age'] < 50), 'Age_cat'] = 4\ndf_train.loc[(50 <= df_train['Age']) & (df_train['Age'] < 60), 'Age_cat'] = 5\ndf_train.loc[(60 <= df_train['Age']) & (df_train['Age'] < 70), 'Age_cat'] = 6\ndf_train.loc[70 <= df_train['Age'], 'Age_cat'] = 7\n\ndf_test['Age_cat'] = 0\ndf_test.loc[df_test['Age'] < 10, 'Age_cat'] = 0\ndf_test.loc[(10 <= df_test['Age']) & (df_test['Age'] < 20), 'Age_cat'] = 1\ndf_test.loc[(20 <= df_test['Age']) & (df_test['Age'] < 30), 'Age_cat'] = 2\ndf_test.loc[(30 <= df_test['Age']) & (df_test['Age'] < 40), 'Age_cat'] = 3\ndf_test.loc[(40 <= df_test['Age']) & (df_test['Age'] < 50), 'Age_cat'] = 4\ndf_test.loc[(50 <= df_test['Age']) & (df_test['Age'] < 60), 'Age_cat'] = 5\ndf_test.loc[(60 <= df_test['Age']) & (df_test['Age'] < 70), 'Age_cat'] = 6\ndf_test.loc[70 <= df_test['Age'], 'Age_cat'] = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:02.285230Z","iopub.execute_input":"2022-07-08T01:43:02.285929Z","iopub.status.idle":"2022-07-08T01:43:02.313885Z","shell.execute_reply.started":"2022-07-08T01:43:02.285893Z","shell.execute_reply":"2022-07-08T01:43:02.312933Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"markdown","source":"* 두번째로 간단한 함수를 만들어 apply메소드에 넣어주는 방법입니다. \n* 훨씬 수월합니다","metadata":{}},{"cell_type":"code","source":"def category_age(x):\n    if x < 10:\n        return 0\n    elif x < 20:\n        return 1\n    elif x < 30:\n        return 2\n    elif x < 40:\n        return 3\n    elif x < 50:\n        return 4\n    elif x < 60:\n        return 5\n    elif x < 70:\n        return 6\n    else:\n        return 7    \n    \ndf_train['Age_cat_2'] = df_train['Age'].apply(category_age)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:03.196117Z","iopub.execute_input":"2022-07-08T01:43:03.197178Z","iopub.status.idle":"2022-07-08T01:43:03.206015Z","shell.execute_reply.started":"2022-07-08T01:43:03.197140Z","shell.execute_reply":"2022-07-08T01:43:03.204980Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"markdown","source":"* 두가지 방법이 잘 적용되었다면, 둘다 같은 결과를 내야합니다\n\n* 이를 확인하기 위해 Series간 boolean 비교 후 all()메소드를 사용합니다. all()메소드는 모든 값이 True면 True, 하나라도 False가 있으면 False를 줍니다","metadata":{}},{"cell_type":"code","source":"print('1번 방법, 2번 방법 둘다 같은 결과를 내면 True 줘야함 -> ', (df_train['Age_cat'] == df_train['Age_cat_2']).all())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:03.786923Z","iopub.execute_input":"2022-07-08T01:43:03.787318Z","iopub.status.idle":"2022-07-08T01:43:03.794285Z","shell.execute_reply.started":"2022-07-08T01:43:03.787286Z","shell.execute_reply":"2022-07-08T01:43:03.793109Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피 True입니다. 둘 중 편한걸 선택하시면 됩니다.\n\n* 이제 중복되는 Age_cat 컬럼과 원래 컬럼 Age를 제거하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['Age', 'Age_cat_2'], axis=1, inplace=True)\ndf_test.drop(['Age'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:04.350689Z","iopub.execute_input":"2022-07-08T01:43:04.351278Z","iopub.status.idle":"2022-07-08T01:43:04.358998Z","shell.execute_reply.started":"2022-07-08T01:43:04.351246Z","shell.execute_reply":"2022-07-08T01:43:04.357883Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Change lnitial, Embarked and Sex (string to numerical)\n\n* 현재 lnitial은 Mr, Mrs, Miss, Master, Other 총 5개로 이루어져 있습니다. 이런 카테고리로 표현되어져 있는 데이터를 모델에 인풋으로 넣어줄 때 우리가 해야할 것은 먼저 컴퓨터가 인식할 수 있도록 수치화 시켜야 합니다.\n\n* map method를 가지고 간단히 할 수 있습니다.\n\n* 사전 순서대로 정리하여 mapping하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial']= df_train['Initial'].map({'Master':0, 'Miss': 1, 'Mr': 2, 'Mrs':3, 'Other':4})\ndf_test['Initial']= df_test['Initial'].map({'Master':0, 'Miss': 1, 'Mr': 2, 'Mrs':3, 'Other':4})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:05.926657Z","iopub.execute_input":"2022-07-08T01:43:05.927254Z","iopub.status.idle":"2022-07-08T01:43:05.935312Z","shell.execute_reply.started":"2022-07-08T01:43:05.927222Z","shell.execute_reply":"2022-07-08T01:43:05.934533Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"markdown","source":"* Embarked도 C, Q, S로 이루어져 있습니다. map을 이용해 바꿔봅시다.\n\n* 그러기 앞서서, 특정 column에 어떤 값들이 있는지 확인해보는 방법을 잠깐 살펴보겠습니다. 간단히 unique()메소드를 쓰거나, value_counts()를 써서 count까지 보는 방법이 있습니다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:08.155508Z","iopub.execute_input":"2022-07-08T01:43:08.156369Z","iopub.status.idle":"2022-07-08T01:43:08.164251Z","shell.execute_reply.started":"2022-07-08T01:43:08.156329Z","shell.execute_reply":"2022-07-08T01:43:08.163478Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:09.849903Z","iopub.execute_input":"2022-07-08T01:43:09.850951Z","iopub.status.idle":"2022-07-08T01:43:09.858090Z","shell.execute_reply.started":"2022-07-08T01:43:09.850913Z","shell.execute_reply":"2022-07-08T01:43:09.857415Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"markdown","source":"* 위 두 방법을 사용해 Embarked가 S, C, Q 세가지로 이루어진 것을 볼 수 있습니다. 이제 map을 사용해봅시다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'] = df_train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\ndf_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:11.798562Z","iopub.execute_input":"2022-07-08T01:43:11.799286Z","iopub.status.idle":"2022-07-08T01:43:11.806325Z","shell.execute_reply.started":"2022-07-08T01:43:11.799250Z","shell.execute_reply":"2022-07-08T01:43:11.805521Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"markdown","source":"* 한번 Null이 사라졌는지 확인해봅시다. Embarked Column만 가져온 것은 하나의 pandas의 Series 객체이므로, isnull()메소드를 사용해 Series의 값들이 null인지 아닌지 대한 boolean 값을 얻을 수 있습니다. 그리고 이것에 any()를 사용하여, Ture가 단하나라도 있을 시 (Null이 한개라도 있을 시) True를 반환해주게 됩니다. 우리는 Null을 S로 다 바꿔주었으므로 False를 얻게됩니다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:34.464573Z","iopub.execute_input":"2022-07-08T01:43:34.464984Z","iopub.status.idle":"2022-07-08T01:43:34.473085Z","shell.execute_reply.started":"2022-07-08T01:43:34.464950Z","shell.execute_reply":"2022-07-08T01:43:34.471713Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"markdown","source":"* Sex 도 Female, male 로 이루어져 있습니다. map 을 이용해 바꿔봅시다.","metadata":{}},{"cell_type":"code","source":"df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\ndf_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:41.091439Z","iopub.execute_input":"2022-07-08T01:43:41.092279Z","iopub.status.idle":"2022-07-08T01:43:41.100298Z","shell.execute_reply.started":"2022-07-08T01:43:41.092236Z","shell.execute_reply":"2022-07-08T01:43:41.099464Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"markdown","source":"* 여지껏 고생하셨습니다. 이제 각 feature 간의 상관관계를 한번 보려고 합니다. 두 변수간의 Pearson correlation 을 구하면 (-1, 1) 사이의 값을 얻을 수 있습니다. -1로 갈수록 음의 상관관계, 1로 갈수록 양의 상관관계를 의미하며, 0은 상관관계가 없다는 것을 의미합니다. 구하는 수식은 아래와 같습니다.","metadata":{}},{"cell_type":"markdown","source":"# 수식","metadata":{}},{"cell_type":"markdown","source":"* 우리는 여러 feature를 가지고 있으니 이를 하나의 maxtrix형태로 보면 편할텐데, 이를 heatmap plot이라고 하며, dataframe의 corr() 메소드와 seaborn을 가지고 편하게 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked', 'FamilySize', 'Initial', 'Age_cat']] \n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0,\n           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 16})\n\ndel heatmap_data","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:47.100438Z","iopub.execute_input":"2022-07-08T01:43:47.100844Z","iopub.status.idle":"2022-07-08T01:43:47.676907Z","shell.execute_reply.started":"2022-07-08T01:43:47.100812Z","shell.execute_reply":"2022-07-08T01:43:47.675489Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 EDA에서 살펴봤듯이, Sex와 Pclass가 Survived에 상관관계가 어느정도 있음을 볼 수 있습니다.\n\n* 생각보다 fare와 Embarked도 상관관계가 있음을 볼 수 있습니다.\n\n* 또한, 우리가 여기서 얻을 수 있는 정보는 서로 강한 상관관계를 가지는 feature들이 없다는 것입니다. \n\n* 이것은 우리가 모델을 학습시킬 때 불필요한(redundant, superfluous) feature가 없다는 것을 의미합니다. 1 또는 -1의 상관관계를 가진 feature A,B가 있다면, 우리가 얻을 수 있는 정보는 사실 하나일거니까요\n\n* 이제 실제로 모델을 학습시키기 앞서서 data preprocessing(전처리)을 진행해보겠습니다.","metadata":{}},{"cell_type":"markdown","source":"## 3.4 One-hot encoding on lnitial and Embarked\n\n* 수치화시킨 카테고리 데이터를 그대로 넣어도 되지만, 모델의 성능을 높이기 위해 one-hot encoding을 해줄 수 있습니다. \n\n* 수치화는 간단히 Master == 0, Miss == 1, Mr == 2,  Mrs == 3, Other ==4로 매핑해주는 것을 말합니다. \n\n* One-hot encoding은 위 카테고리를 아래와 같이 (0,1)로 이루어진 5차원의 벡터로 나타내는 ","metadata":{}},{"cell_type":"markdown","source":"* 보시다시피 오른쪽에 우리가 만들려고 했던 one-hot encoded columns가 생성된 것이 보입니다.\n\n* Embarked 에도 적용하겠습니다. Initial 때와 마찬가지로 one-hot encoding 을 사용해 표현하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\ndf_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:51.428350Z","iopub.execute_input":"2022-07-08T01:43:51.428739Z","iopub.status.idle":"2022-07-08T01:43:51.444436Z","shell.execute_reply.started":"2022-07-08T01:43:51.428709Z","shell.execute_reply":"2022-07-08T01:43:51.443195Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:53.350535Z","iopub.execute_input":"2022-07-08T01:43:53.350950Z","iopub.status.idle":"2022-07-08T01:43:53.369878Z","shell.execute_reply.started":"2022-07-08T01:43:53.350908Z","shell.execute_reply":"2022-07-08T01:43:53.368681Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')\ndf_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:43:54.489225Z","iopub.execute_input":"2022-07-08T01:43:54.489601Z","iopub.status.idle":"2022-07-08T01:43:54.505845Z","shell.execute_reply.started":"2022-07-08T01:43:54.489570Z","shell.execute_reply":"2022-07-08T01:43:54.504608Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:10.263366Z","iopub.execute_input":"2022-07-08T01:44:10.263745Z","iopub.status.idle":"2022-07-08T01:44:10.283482Z","shell.execute_reply.started":"2022-07-08T01:44:10.263715Z","shell.execute_reply":"2022-07-08T01:44:10.282380Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"markdown","source":"* 아주 쉽게 one-hot encoding을 적용했습니다. \n\n* sklearn로 Labelencoder + OneHotencoder 이용해도 one-hot encoding이 가능합니다.\n\n* 다른 튜토리얼에서 한번 써보겠습니다. 여기서는 get-dummies로 충분히 가능하기 때문에 get-dummies만으로 끝내겠습니다.\n\n* 가끔 catrgory가 100개가 넘어가는 경우가 있습니다. 이때 one-hot encoding을 사용하면 column이 100가 생겨, 학습시 매우 버거울 경우가 있습니다. 이런 경우는 다른 ㅂㅇ법을 사용하기도 하는데, 이는 다음에 한번 다뤄보겠습니다","metadata":{}},{"cell_type":"markdown","source":"## 3.5 Drop columns","metadata":{}},{"cell_type":"code","source":"df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n\ndf_test.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:20.660004Z","iopub.execute_input":"2022-07-08T01:44:20.660393Z","iopub.status.idle":"2022-07-08T01:44:20.672064Z","shell.execute_reply.started":"2022-07-08T01:44:20.660360Z","shell.execute_reply":"2022-07-08T01:44:20.671074Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:22.868633Z","iopub.execute_input":"2022-07-08T01:44:22.869664Z","iopub.status.idle":"2022-07-08T01:44:22.886093Z","shell.execute_reply.started":"2022-07-08T01:44:22.869614Z","shell.execute_reply":"2022-07-08T01:44:22.884846Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:27.949448Z","iopub.execute_input":"2022-07-08T01:44:27.949833Z","iopub.status.idle":"2022-07-08T01:44:27.966672Z","shell.execute_reply.started":"2022-07-08T01:44:27.949801Z","shell.execute_reply":"2022-07-08T01:44:27.965844Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"markdown","source":"* 보시다시피, train의 Survived feature(target class)를 빼면 train, test 둘다 같은 columns를 가진 걸 확인 할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"# 4. Building machine learning model and prediction using the trained model\n\n* 이제 준비가 다 되었으니 sklearn을 사용해 본격적으로 머신러닝 모델을 만들어 봅시다.","metadata":{}},{"cell_type":"code","source":"#importing all the required ML packages\nfrom sklearn.ensemble import RandomForestClassifier # 유명한 randomforestclassfier 입니다. \nfrom sklearn import metrics # 모델의 평가를 위해서 씁니다\nfrom sklearn.model_selection import train_test_split # traning set을 쉽게 나눠주는 함수입니다.","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:49.896880Z","iopub.execute_input":"2022-07-08T01:44:49.897265Z","iopub.status.idle":"2022-07-08T01:44:49.902659Z","shell.execute_reply.started":"2022-07-08T01:44:49.897233Z","shell.execute_reply":"2022-07-08T01:44:49.901714Z"},"trusted":true},"execution_count":262,"outputs":[]},{"cell_type":"markdown","source":"* Sklearn은 머신러닝의 처음부터 끝까지가 다 있습니다. feature engineering, preprocessing, 지도학습 알고리즘, 비지도 학습 알고리즘, 모델평가, 파이프라인 등 머신러닝에 관련된 모든 작업들이 손쉬운 인터페이스로 구현되어 있습니다. 데이터 분석 + 머신러닝을 하고싶다면, 이 라이브러리는 반드시 숙지해야합니다.\n\n* 파이썬 라이브러리를 활용한 머신러닝(Introduction to machine larning with Python)책을 사서 공부하시길 매우 추천드립니다.","metadata":{}},{"cell_type":"markdown","source":"* 지금 타이타닉 문제는 tatget class(survived)가 있으며, target class는 0,1로 이루어져 있으므로 (binary) binary classfication 문제입니다.\n\n* 우리가 지금 가지고 있는 train set의 survived를 제외한 input을 가지고 모델을 최적화시켜서 각 샘플(탑승객)의 생존 유무를 판단하는 모델을 만들어 냅니다.\n\n* 그후 모델이 학습하지 않았던 test set을 input으로 주어서 test set의 각 샘플(탑승객)의 생존 유무를 예측해봅시다","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Preparation - Split dataset into train, valid, test set\n\n* 가장 먼저, 학습에 쓰일 데이터와 target label(Survived)를 분리합니다. drop을 사용해 간단히 할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_train = df_train.drop('Survived', axis=1).values\ntarget_label = df_train['Survived'].values\nX_test = df_test.values","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:53.446098Z","iopub.execute_input":"2022-07-08T01:44:53.446514Z","iopub.status.idle":"2022-07-08T01:44:53.454578Z","shell.execute_reply.started":"2022-07-08T01:44:53.446479Z","shell.execute_reply":"2022-07-08T01:44:53.453460Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"markdown","source":"* 보통 train, test 만 언급되지만, 실제 좋은 모델을 만들기 위해서 우리는 valid set을 따로 만들어 모델 평가를 해봅니다.\n\n* 마치 축구대표팀이 팀훈련(train)을 하고 바로 월드컵(test)로 나가는 것이 아니라, 팀훈련(train)을 한 다음 평가전(valid)를 거쳐 팀의 훈련 정도(학습정도)를 확인하고 월드컵(test)에 나가는 것과 비슷합니다.\n\n* train_test_split 을 사용하여 쉽게 train 셋을 분리할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:44:59.712736Z","iopub.execute_input":"2022-07-08T01:44:59.713139Z","iopub.status.idle":"2022-07-08T01:44:59.719436Z","shell.execute_reply.started":"2022-07-08T01:44:59.713106Z","shell.execute_reply":"2022-07-08T01:44:59.718575Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"markdown","source":"* sklearn 에서는 여러 머신러닝 알고리즘을 지원해줍니다. 열거하기엔 너무 많으므로, 직접 documentation에 들어가 보시길 추천합니다. http://scikit-learn.org/stable/supervised_learning.html#supervised-learning 여기에 들어가시면 지원되는 알고리즘 수에 놀라실 겁니다.\n\n* 본 튜토리얼에서는 랜덤포레스트 모델을 사용하도록 하겠습니다.\n\n* 랜덤포레스트는 결정트리기반 모델이며, 여러 결정 트리들을 앙상블한 모델입니다. 더 구체적인 모델 설명은 여러 블로그들 참고하시면 될 것이고, 저도 한번 추후 다뤄보겠습니다\n\n* 각 머신러닝 알고리즘에는 여러 파라미터들이 있습니다. 랜덤포레스트분류기도 n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf 등 여러 파라미터들이 존재합니다. 이것들이 어떻게 세팅되냐에 따라 같은 데이터셋이라 하더라도 모델의 성능이 달라집니다.\n\n* 파라미터 튜닝은 시간, 경험, 알고리즘에 대한 이해 등이 필요합니다. 결국 많이 써봐야 모델도 잘 세울 수 있는 것이죠. 그래서 캐글을 추천합니다. 여러 데이터셋을 가지고 모델을 이리저리 써봐야 튜닝하는 감이 생길테니까요!\n\n* 일단 지금은 튜토리얼이니 파라미터 튜닝은 잠시 제쳐두기로 하고, 기본 default 세팅으로 진행하겠습니다.\n\n* 모델 객체를 만들고, fit 메소드로 학습시킵니다\n\n* 그런 후 valid set input 을 넣어주어 예측값(X_vld sample(탑승객)의 생존여부)를 얻습니다.","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Model generation and prediction","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_tr, y_tr)\nprediction = model.predict(X_vld)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:02.781858Z","iopub.execute_input":"2022-07-08T01:45:02.782870Z","iopub.status.idle":"2022-07-08T01:45:03.011166Z","shell.execute_reply.started":"2022-07-08T01:45:02.782831Z","shell.execute_reply":"2022-07-08T01:45:03.009846Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"markdown","source":"* 단 세줄만으로 여러분은 모델을 세우고,예측까지 해봤습니다. \n* 자, 이제 모델의 성능을 한번 살펴보겠습니다","metadata":{}},{"cell_type":"code","source":"print('총 {}명 중 {:.2f}% 정확도로 생존을 맞춤'.format(y_vld.shape[0], 100 * metrics.accuracy_score(prediction, y_vld)))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:04.819159Z","iopub.execute_input":"2022-07-08T01:45:04.819702Z","iopub.status.idle":"2022-07-08T01:45:04.827234Z","shell.execute_reply.started":"2022-07-08T01:45:04.819657Z","shell.execute_reply":"2022-07-08T01:45:04.825986Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"markdown","source":"* 아무런 파라미터 튜닝도 하지 않았는데 82%의 정확도가 나왔습니다. 고생하셨습니다.","metadata":{}},{"cell_type":"markdown","source":"## 4.3 Feature importance\n\n* 학습된 모델은 feature importance 를 가지게 되는데, 우리는 이것을 확인하여 지금 만든 모델이 어떤 feature 에 영향을 많이 받았는 지 확인할 수 있습니다.\n\n* 쉽게 말해, 10 = 4x1 + 2x2 + 1*x3 을 생각하면, 우리는 x1이 결과값(10)에 큰 영향을 준다고 생각 할 수 있습니다. feature importance 는 4, 2, 1 을 이야기하며, x1이 가장 큰 값(4)를 가지므로, 이 모델에 가장 큰 영향을 미친다고 말할 수 있습니다.\n\n* 학습된 모델은 기본적으로 featureimportances 를 가지고 있어서 쉽게 그 수치를 얻을 수 있습니다.\n\n* pandas series 를 이용하면 쉽게 sorting 을 하여 그래프를 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"from pandas import Series\n\nfeature_importance = model.feature_importances_\nSeries_feat_imp = Series(feature_importance, index=df_test.columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:08.206032Z","iopub.execute_input":"2022-07-08T01:45:08.207005Z","iopub.status.idle":"2022-07-08T01:45:08.224523Z","shell.execute_reply.started":"2022-07-08T01:45:08.206953Z","shell.execute_reply":"2022-07-08T01:45:08.223569Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nSeries_feat_imp.sort_values(ascending=True).plot.barh()\nplt.xlabel('Feature importance')\nplt.ylabel('Feature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:10.587035Z","iopub.execute_input":"2022-07-08T01:45:10.587895Z","iopub.status.idle":"2022-07-08T01:45:10.823121Z","shell.execute_reply.started":"2022-07-08T01:45:10.587855Z","shell.execute_reply":"2022-07-08T01:45:10.821851Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 얻은 모델에서는 Fare 가 가장 큰 영향력을 가지며, 그 뒤로 Initial_2, Age_cat, Pclass가 차례로 중요도를 가집니다\n\n* 사실 feature importance 는 지금 모델에서의 importance 를 나타냅니다. 만약 다른 모델을 사용하게 된다면 feature importance 가 다르게 나올 수 있습니다.\n\n* 이 feature importance 를 보고 실제로 Fare 가 중요한 feature 일 수 있다고 판단을 내릴 수는 있지만, 이것은 결국 모델에 귀속되는 하나의 결론이므로 통계적으로 좀 더 살펴보긴 해야합니다.\n\n* featuure importance 를 가지고 좀 더 정확도가 높은 모델을 얻기 위해 feature selection 을 할 수도 있고, 좀 더 빠른 모델을 위해 feature 제거를 할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"## 4.4 Prediction on Test set\n\n* 이제 모델이 학습하지 않았던(보지 않았던) 테스트셋을 모델에 주어서, 생존여부를 예측해보겠습니다\n\n* 이 결과는 실제로 submission(제출용) 이므로 결과는 leaderboard 에서 확인할 수 있습니다.\n\n* 캐글에서 준 파일, gender_submission.csv 파일을 읽어서 제출 준비를 하겠습니다.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:15.814472Z","iopub.execute_input":"2022-07-08T01:45:15.814849Z","iopub.status.idle":"2022-07-08T01:45:15.825298Z","shell.execute_reply.started":"2022-07-08T01:45:15.814817Z","shell.execute_reply":"2022-07-08T01:45:15.824190Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:24.433108Z","iopub.execute_input":"2022-07-08T01:45:24.434099Z","iopub.status.idle":"2022-07-08T01:45:24.443152Z","shell.execute_reply.started":"2022-07-08T01:45:24.434055Z","shell.execute_reply":"2022-07-08T01:45:24.442207Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"markdown","source":"* 이제 testset에 대하여 예측을 하고 결과를 csv 파일로 저장해보겠습니다.","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(X_test)\nsubmission['Survived'] = prediction","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:28.782832Z","iopub.execute_input":"2022-07-08T01:45:28.783212Z","iopub.status.idle":"2022-07-08T01:45:28.808850Z","shell.execute_reply.started":"2022-07-08T01:45:28.783182Z","shell.execute_reply":"2022-07-08T01:45:28.808020Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('./my_first_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T01:45:31.390857Z","iopub.execute_input":"2022-07-08T01:45:31.391224Z","iopub.status.idle":"2022-07-08T01:45:31.399284Z","shell.execute_reply.started":"2022-07-08T01:45:31.391194Z","shell.execute_reply":"2022-07-08T01:45:31.398137Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"markdown","source":"* 이제 캐글에 제출해보도록 합시다","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}